name: Testing

on:
  workflow_call:
    inputs:
      docker_image:
        description: Docker image to use in tests
        required: true
        type: string
      runner_label:
        description: Label of the runner specified in Build workflow
        required: true
        type: string
      board_target:
        description: Target board for the build
        required: true
        type: string
      device_serial:
        description: Serial device for connecting target board
        required: true
        type: string
      test_tag:
        description: Test TAGs to filter tests
        required: false
        type: string
      pytest_args:
        description: Arguments to the pytest subprocess (extend YAML config)
        required: false
        type: string
      test_scenario:
        description: Test suite scenario to run
        required: false
        type: string
      tests_target:
        description: Tests scope to run
        required: true
        default: app/repo
        type: string
      integration_tests:
        description: Condition to run integration tests only
        required: false
        type: string

env:
  # Pass all secrets as json to jobs
  SECRETS_JSON: ${{ toJSON(secrets) }}

jobs:
  testing:
    name: Start testing
    runs-on: ${{ inputs.runner_label }}
    outputs:
      test_type: ${{ inputs.tests_target }}
      label: ${{ inputs.runner_label }}
    defaults:
      run:
        working-directory: customer-application
    container:
      image: ${{ inputs.docker_image }}
      options: >
        --device=/dev/ttyUSB0 
        --privileged  
        -v /var/run/dbus:/var/run/dbus 
        -v /run/dbus:/run/dbus 
        -v /dev:/dev 
        -e DBUS_SESSION_BUS_ADDRESS=unix:path=/run/dbus/system_bus_socket
    env:
      CMAKE_PREFIX_PATH: /opt/toolchains
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          path: customer-application
      
      # Initiate Zephyr environment
      - name: Initialize
        shell: bash
        run: |
            echo "Checking out Zephyr env..."
            pwd
            echo "Current github workspace:"
            ls -la
            echo "Parent github folder"
            ls -la ..
            rm -rf ../.west
            west init -l .
            west update -o=--depth=1 -n
            west blobs fetch hal_espressif
            
      # Install lib extras for testing
      - name: Install lib extras
        shell: bash
        run: |
            sudo apt-get update
            sudo apt-get install -y iperf
            sudo apt-get install -y sysbench fio

      # Install Python extras for testing
      - name: Install Python extra packages
        shell: bash
        run: |
            pip install -r requirements-extras.txt

      #  Review of variables from Build workflow
      - name: Show variables from caller workflow
        shell: bash
        run: |
            echo "Variables from caller workflow:"
            echo "docker_image: ${{ inputs.docker_image }}"
            echo "runner_label: ${{ inputs.runner_label }}"
            echo "integration_tests: ${{ inputs.integration_tests }}"
            echo "board_target: ${{ inputs.board_target }}"
            echo "device_serial: ${{ inputs.device_serial }}"
            echo "tests_target: ${{ inputs.tests_target }}"
            echo "test_scenario: ${{ inputs.test_scenario }}"
            echo "test_tag: ${{ inputs.test_tag }}"
            echo "pytest_args: ${{ inputs.pytest_args }}"
            
      # Generate list of all tests in application in json-format
      - name: Create list of all application tests
        shell: bash
        # No test scenario is filtered
        run: python .github/scripts/tests_yaml_parser.py

      # Generate tests paths to run with twister command
      - name: Create test list with tests scope
        shell: bash
        # No test scenario is filtered
        if : ${{ inputs.test_scenario == 'N/A' || '' }} 
        run: python .github/scripts/get_tests_list.py --tests_scope ${{ inputs.tests_target }}

      - name: Create test list with test scenario
        shell: bash
        # Specific test scenario is filtered
        if : ${{ inputs.test_scenario != 'N/A' || '' }} 
        run: python .github/scripts/get_tests_list.py --tests_scenario ${{ inputs.tests_target }} 
        
      - name: Create test list with robot tests
        shell: bash
        # Specific test scenario is filtered
        if : ${{ inputs.tests_target == 'app/robot' }} 
        run: python .github/scripts/get_tests_list.py --tests_robot ${{ inputs.tests_target }} 

      # Put list of testcases into output variable for shell script usage
      - name: Get tests list
        shell: python
        id: py-script
        run: |
            import os
            import re
            regex = re.compile('.*_tests.txt')
            for dir in os.listdir('.'):
                if regex.match(dir):
                  with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                    f.write(f'test_list={os.path.join(dir)}\n')

      # Pass secrets for tests into json file
      - name: Create json file with secrets variables
        shell: bash
        run: |
            echo $SECRETS_JSON > vars.json
            cat vars.json

      # Run Twister tests
      - name: Run Twister tests
        shell: bash
        run: |
            python .github/scripts/run_tests.py --platform ${{ inputs.board_target }} \
            --device_serial ${{ inputs.device_serial }} \
            --tag ${{ inputs.test_tag }} \
            --pytest_args ${{ inputs.pytest_args }} \
            --scenario ${{ inputs.test_scenario }} \
            --test_list ${{steps.py-script.outputs.test_list}} \
            --target ${{ inputs.tests_target }} \
            --integration_tests ${{ inputs.integration_tests }}

      # Archive all test artifacts except Robot tests
      - name: Single test artifacts for non-Robot tests
        uses: actions/upload-artifact@v4
        continue-on-error: true
        if: ${{ inputs.tests_target != 'app/robot' }} 
        with:
          name: single_test_artifacts
          # Relative path to project root. 
          path: |
            customer-application/twister-out*/*
          include-hidden-files: true
          if-no-files-found: error
          retention-days: 5

      # Upload xml files for test statistics to artifacts
      - name: Upload all twister_suite_report.xml to artifacts
        uses: actions/upload-artifact@v4
        continue-on-error: true
        with:
          name: xml_statistics_artifacts
          # Relative path to project root. 
          path: |
            customer-application/twister-out*/twister_suite_report.xml
          retention-days: 5

      # Archive robot tests artifacts
      - name: Archive test summary artifacts for Robot-tests
        uses: actions/upload-artifact@v4
        continue-on-error: true
        if: ${{ inputs.tests_target == 'app/robot' }} 
        with:
          name: single_test_artifacts
          # Relative path to project root. 
          path: |
            customer-application/pabot_results/*
          if-no-files-found: error
          retention-days: 5
      
      # Prepare test summary report folder
      - name: Prepare CI report summary for non-Robot tests
        shell: bash
        if : ${{ inputs.tests_target != 'app/robot' }} 
        run: |
            rm -rf test-summary
            sudo mkdir -p test-summary

      # Collect all test summary reports into one folder
      - name: Copy files to CI report summary
        shell: python
        if : ${{ inputs.tests_target != 'app/robot' }} 
        run: |
            import os
            import re
            import shutil
            regex = re.compile('twister-out.*')
            for dir in os.listdir('.'):
              if regex.match(dir):
                print(f"Found: {dir}")
                if os.path.exists(os.path.join(dir, "twister_suite_report.xml")):
                  shutil.copyfile(os.path.join(dir, "twister_suite_report.xml"), \
                  os.path.join("test-summary", \
                  f"twister_suite_report{dir.split('-out')[1]}.xml"))
                else:
                  print(f"File twister_suite_report.xml not found in {dir}")


      # Archive test summary report
      - name: Archive test summary artifacts for non-Robot tests
        uses: actions/upload-artifact@v4
        continue-on-error: true
        if: ${{ inputs.tests_target != 'app/robot' }} 
        with:
          name: summary_test_artifacts
          # Relative path to project root. 
          path: |
            customer-application/test-summary
          if-no-files-found: error
          retention-days: 5


  publish_test_summaries:
    name: Publish Test Summaries
    if: ${{ needs.testing.outputs.test_type != 'app/robot' }}
    needs: testing
    uses: ./.github/workflows/reports-summary-publish.yml
    with:
      runner: ${{ needs.testing.outputs.label }}
